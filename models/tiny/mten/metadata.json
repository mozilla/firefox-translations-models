{
  "architecture": "tiny",
  "byteSize": 17140836,
  "flores": {
    "bleu": 42.7,
    "comet": 0.7619
  },
  "hash": "7d86de7e2136b5ecf0b61f5cbd01418a1fdbb52f08b8eb9d7dfe2379bbdf2486",
  "modelConfig": {
    "bert-train-type-embeddings": true,
    "bert-type-vocab-size": 2,
    "dec-cell": "ssru",
    "dec-cell-base-depth": 2,
    "dec-cell-high-depth": 1,
    "dec-depth": 2,
    "dim-emb": 256,
    "dim-rnn": 1024,
    "dim-vocabs": [
      32000,
      32000
    ],
    "enc-cell": "gru",
    "enc-cell-depth": 1,
    "enc-depth": 6,
    "enc-type": "bidirectional",
    "input-types": [],
    "layer-normalization": false,
    "lemma-dim-emb": 0,
    "output-omit-bias": false,
    "right-left": false,
    "skip": false,
    "tied-embeddings": false,
    "tied-embeddings-all": true,
    "tied-embeddings-src": false,
    "transformer-aan-activation": "swish",
    "transformer-aan-depth": 2,
    "transformer-aan-nogate": false,
    "transformer-decoder-autoreg": "rnn",
    "transformer-dim-aan": 2048,
    "transformer-dim-ffn": 1536,
    "transformer-ffn-activation": "relu",
    "transformer-ffn-depth": 2,
    "transformer-guided-alignment-layer": "last",
    "transformer-heads": 8,
    "transformer-no-projection": false,
    "transformer-pool": false,
    "transformer-postprocess": "dan",
    "transformer-postprocess-emb": "d",
    "transformer-postprocess-top": "",
    "transformer-preprocess": "",
    "transformer-tied-layers": [],
    "transformer-train-position-embeddings": false,
    "type": "transformer",
    "ulr": false,
    "ulr-dim-emb": 0,
    "ulr-trainable-transformation": false,
    "version": "v1.9.56 dad4d507 2021-06-28 12:10:40 +0100"
  },
  "modelStatistics": {
    "decoder_bytes": 2524224,
    "decoder_parameters": 2400528,
    "embeddings_bytes": 8192000,
    "encoder_bytes": 6383760,
    "encoder_parameters": 6314532,
    "parameters": 16907062
  },
  "sourceLanguage": "mt",
  "targetLanguage": "en",
  "version": "1.0a1"
}
