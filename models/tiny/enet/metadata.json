{
  "architecture": "tiny",
  "byteSize": 17140754,
  "flores": {
    "bleu": 25.6,
    "comet": 0.8739
  },
  "hash": "a28874a8b702a519a14dc71bcee726a5cb4b539eeaada2d06492f751469a1fd6",
  "modelConfig": {
    "bert-train-type-embeddings": true,
    "bert-type-vocab-size": 2,
    "dec-cell": "ssru",
    "dec-cell-base-depth": 2,
    "dec-cell-high-depth": 1,
    "dec-depth": 2,
    "dim-emb": 256,
    "dim-rnn": 1024,
    "dim-vocabs": [
      32000,
      32000
    ],
    "enc-cell": "gru",
    "enc-cell-depth": 1,
    "enc-depth": 6,
    "enc-type": "bidirectional",
    "input-types": [],
    "layer-normalization": false,
    "lemma-dim-emb": 0,
    "right-left": false,
    "skip": false,
    "tied-embeddings": false,
    "tied-embeddings-all": true,
    "tied-embeddings-src": false,
    "transformer-aan-activation": "swish",
    "transformer-aan-depth": 2,
    "transformer-aan-nogate": false,
    "transformer-decoder-autoreg": "rnn",
    "transformer-dim-aan": 2048,
    "transformer-dim-ffn": 1536,
    "transformer-ffn-activation": "relu",
    "transformer-ffn-depth": 2,
    "transformer-guided-alignment-layer": "last",
    "transformer-heads": 8,
    "transformer-no-projection": false,
    "transformer-postprocess": "dan",
    "transformer-postprocess-emb": "d",
    "transformer-preprocess": "",
    "transformer-tied-layers": [],
    "transformer-train-position-embeddings": false,
    "type": "transformer",
    "ulr": false,
    "ulr-dim-emb": 0,
    "ulr-trainable-transformation": false,
    "version": "v1.8.0 6331531 2019-09-09 22:19:00 +0200"
  },
  "modelStatistics": {
    "decoder_bytes": 2524224,
    "decoder_parameters": 2400528,
    "embeddings_bytes": 8192000,
    "encoder_bytes": 6383760,
    "encoder_parameters": 6314532,
    "parameters": 16907062
  },
  "sourceLanguage": "en",
  "targetLanguage": "et",
  "version": "1.0"
}
